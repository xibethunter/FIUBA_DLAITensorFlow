{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W4/assignment/C1W4_Assignment_traducido.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvJbBW_oDOwC"
   },
   "source": [
    "# Semana 4: Manejo de imágenes complejas - Conjunto de datos feliz o triste\n",
    "\n",
    "En esta tarea se utilizará el conjunto de datos Feliz o Triste, que contiene 80 imágenes de caras tipo emoji, 40 felices y 40 tristes.\n",
    "\n",
    "Cree una red neuronal convolucional que se entrene con una precisión del 99,9% en estas imágenes, y que cancele el entrenamiento al alcanzar este umbral de precisión.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "# Week 4: Handling Complex Images - Happy or Sad Dataset\n",
    "\n",
    "In this assignment you will be using the happy or sad dataset, which contains 80 images of emoji-like faces, 40 happy and 40 sad.\n",
    "\n",
    "Create a convolutional neural network that trains to 99.9% accuracy on these images,  which cancels training upon hitting this training accuracy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NFuMFYXtwsT",
    "outputId": "723d6bc3-c7cd-491b-d6f8-49a2e404a0a2",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y explorar los datos\n",
    "\n",
    "Comience por echar un vistazo a algunas imágenes del conjunto de datos.\n",
    "\n",
    "Observa que todas las imágenes están contenidas en el directorio `./data/`. \n",
    "\n",
    "Este directorio contiene dos subdirectorios `feliz/` y `triste/` y cada imagen se guarda en el subdirectorio relacionado con la clase a la que pertenece.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Load and explore the data\n",
    "\n",
    "Begin by taking a look at some images of the dataset.\n",
    "\n",
    "Notice that all the images are contained within the `./data/` directory. \n",
    "\n",
    "This directory contains two subdirectories `happy/` and `sad/` and each image is saved under the subdirectory related to the class it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "uaWTfp5Ox9E-",
    "outputId": "1a4b4b15-9a5f-4fd3-8c56-b32d47ae0893",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "base_dir = \"./data/\"\n",
    "happy_dir = os.path.join(base_dir, \"happy/\")\n",
    "sad_dir = os.path.join(base_dir, \"sad/\")\n",
    "\n",
    "print(\"Sample happy image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSample sad image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es genial poder ver ejemplos de las imágenes para entender mejor el espacio-problema con el que se está tratando. \n",
    "\n",
    "Sin embargo, todavía falta alguna información relevante como la resolución de la imagen (aunque matplotlib renderiza las imágenes en una cuadrícula proporcionando una buena idea de estos valores) y el valor máximo de los píxeles (esto es importante para normalizar estos valores). Para ello se puede utilizar Keras como se muestra en la siguiente celda:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "It is cool to be able to see examples of the images to better understand the problem-space you are dealing with. \n",
    "\n",
    "However there is still some relevant information that is missing such as the resolution of the image (although matplotlib renders the images in a grid providing a good idea of these values) and the maximum pixel value (this is important for normalizing these values). For this you can use Keras as shown in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Cargar el primer ejemplo de una cara feliz\n",
    "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
    "\n",
    "# Convierte la imagen en su representación de matriz numpy\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Each image has shape: {sample_array.shape}\")\n",
    "\n",
    "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que las imágenes tienen una resolución de 150x150. **Esto es muy importante porque este será el tamaño de entrada de la primera capa de tu red.** \n",
    "\n",
    "**La última dimensión se refiere a cada uno de los 3 canales RGB que se utilizan para representar las imágenes en color.**\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Looks like the images have a resolution of 150x150. **This is very important because this will be the input size of the first layer in your network.** \n",
    "\n",
    "**The last dimension refers to each one of the 3 RGB channels that are used to represent colored images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la llamada de retorno\n",
    "\n",
    "Como ya has codificado la llamada de retorno responsable de detener el entrenamiento (una vez que se alcanza un nivel de precisión deseado) en las dos tareas anteriores, esta vez ya se proporciona para que puedas centrarte en los otros pasos:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Defining the callback\n",
    "\n",
    "Since you already have coded the callback responsible for stopping training (once a desired level of accuracy is reached) in the previous two assignments this time it is already provided so you can focus on the other steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0UOFLauzIW4",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una nota rápida sobre las devoluciones de llamada: \n",
    "\n",
    "Hasta ahora sólo has utilizado la llamada de retorno `on_epoch_end` pero hay muchas más. Por ejemplo, puede que quieras echar un vistazo a la devolución de llamada [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), que te permite guardar los mejores pesos para tu modelo.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "A quick note on callbacks: \n",
    "\n",
    "So far you have used only the `on_epoch_end` callback but there are many more. For example you might want to check out the [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback, which allows you to save the best weights for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de los datos\n",
    "\n",
    "Keras proporciona un gran soporte para el preprocesamiento de datos de imágenes. Se puede lograr mucho utilizando la clase `ImageDataGenerator`. Asegúrate de revisar los [docs](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) si te atascas en el siguiente ejercicio. En particular, debes prestar atención al argumento `rescale` al instanciar el `ImageDataGenerator` y al método [`flow_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory).\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Pre-processing the data\n",
    "\n",
    "Keras provides great support for preprocessing image data. A lot can be accomplished by using the `ImageDataGenerator` class. Be sure to check out the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) if you get stuck in the next exercise. In particular you might want to pay attention to the `rescale` argument when instantiating the `ImageDataGenerator` and to the [`flow_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "rrGO8ObGzqht",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GRADED FUNCTION: image_generator\n",
    "def image_generator():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Instanciar la clase ImageDataGenerator.\n",
    "    # Recuerda establecer el argumento de reescalado.\n",
    "    train_datagen = None\n",
    "\n",
    "    # Especifica el método para cargar las imágenes desde un directorio y pasa los argumentos adecuados:\n",
    "    # - directory: debe ser una ruta relativa al directorio que contiene los datos\n",
    "    # - targe_size: establecerlo igual a la resolución de cada imagen (excluyendo la dimensión de color)\n",
    "    # - batch_size: número de imágenes que el generador produce cuando se le pide un siguiente lote. Establézcalo en 10.\n",
    "    # - class_mode: Cómo se representan las etiquetas. Debe ser uno de \"binario\", \"categórico\" o \"disperso\".\n",
    "    # Escoge el que mejor se adapte aquí dado que las etiquetas van a ser etiquetas binarias 1D.\n",
    "    train_generator = train_datagen.flow_from_directory(directory=None,\n",
    "                                                        target_size=(None, None),\n",
    "                                                        batch_size=None,\n",
    "                                                        class_mode=None)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return train_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9uxJFQb1nOx",
    "outputId": "0c6ce535-7764-4bc0-a4a4-e6289a360b04",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Guarda tu generador en una variable\n",
    "gen = image_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "```\n",
    "Se han encontrado 80 imágenes pertenecientes a 2 clases.\n",
    "```\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "Found 80 images belonging to 2 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento del modelo\n",
    "\n",
    "Finalmente, completa la función `train_happy_sad_model` que aparece a continuación. Esta función debería devolver tu red neuronal.\n",
    "\n",
    "**Tu modelo debe alcanzar una precisión del 99,9% o más antes de 15 épocas para aprobar esta tarea.\n",
    "\n",
    "**Pistas:**\n",
    "- Puedes probar cualquier arquitectura para la red pero ten en cuenta que el modelo funcionará mejor con 3 capas convolucionales. \n",
    "\n",
    "\n",
    "- En caso de que necesites ayuda extra puedes consultar algunos consejos al final de este cuaderno.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Creating and training your model\n",
    "\n",
    "Finally, complete the `train_happy_sad_model` function below. This function should return your  neural network.\n",
    "\n",
    "**Your model should achieve an accuracy of 99.9% or more before 15 epochs to pass this assignment.**\n",
    "\n",
    "**Hints:**\n",
    "- You can try any architecture for the network but keep in mind that the model will work best with 3 convolutional layers. \n",
    "\n",
    "\n",
    "- In case you need extra help you can check out some tips at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUcNTpra1FK0",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses\n",
    "\n",
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model(train_generator):\n",
    "\n",
    "    # Instanciar el Callback\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = tf.keras.models.Sequential([\n",
    "        None,\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    # Selecciona una función de pérdida compatible con la última capa de tu red\n",
    "    model.compile(loss=losses.None,\n",
    "                  optimizer=optimizers.None,\n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "\n",
    "\n",
    "    # Entrena el modelo\n",
    "    # Tu modelo debería alcanzar la precisión deseada en menos de 15 epochs.\n",
    "    # Puede codificar hasta 20 épocas en la función de abajo, pero la llamada de retorno debe activarse antes de 15.\n",
    "    history = model.fit(x=None,\n",
    "                        epochs=None,\n",
    "                        callbacks=[None]\n",
    "                       ) \n",
    "    \n",
    "    ### END CODE HERE\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSaPPUe_z_OU",
    "outputId": "b6e6306a-8b28-463b-e1a0-8bdeb9116f26",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "hist = train_happy_sad_model(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ves el mensaje que se definió en el callback impreso después de menos de 15 épocas significa que tu callback funcionó como se esperaba y el entrenamiento fue exitoso. También puede comprobarlo ejecutando la siguiente celda:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "If you see the message that was defined in the callback printed out after less than 15 epochs it means your callback worked as expected and training was successful. You can also double check by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0imravDn0Ajz",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Your model reached the desired accuracy after {len(hist.epoch)} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si su llamada de retorno no detiene el entrenamiento, una de las causas puede ser que haya compilado su modelo utilizando una métrica diferente a la de `precisión` (como `acc`). Asegúrate de que has configurado la métrica como `precisión`. Puedes comprobarlo ejecutando la siguiente celda:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "If your callback didn't stop training, one cause might be that you compiled your model using a metric other than `accuracy` (such as `acc`). Make sure you set the metric to `accuracy`. You can check by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"accuracy\" in hist.model.metrics_names:\n",
    "    print(\"Use 'accuracy' as metric when compiling your model.\")\n",
    "else:\n",
    "    print(\"The metric was correctly defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Necesitas más ayuda?\n",
    "\n",
    "Ejecute la siguiente celda para ver algunos consejos adicionales para la arquitectura del modelo.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Need more help?\n",
    "\n",
    "Run the following cell to see some extra tips for the model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "encoded_answer = \"ClNvbWUgaGVscGZ1bCB0aXBzIGluIGNhc2UgeW91IGFyZSBzdHVjazoKCiAgICAtIEEgZ29vZCBmaXJzdCBsYXllciB3b3VsZCBiZSBhIENvbnYyRCBsYXllciB3aXRoIGFuIGlucHV0IHNoYXBlIHRoYXQgbWF0Y2hlcyAKICAgIHRoYXQgb2YgZXZlcnkgaW1hZ2UgaW4gdGhlIHRyYWluaW5nIHNldCAoaW5jbHVkaW5nIHRoZSBjb2xvciBkaW1lbnNpb24pCiAgICAKICAgIC0gVGhlIG1vZGVsIHdpbGwgd29yayBiZXN0IHdpdGggMyBjb252b2x1dGlvbmFsIGxheWVycwogICAgCiAgICAtIFRoZXJlIHNob3VsZCBiZSBhIEZsYXR0ZW4gbGF5ZXIgaW4gYmV0d2VlbiBjb252b2x1dGlvbmFsIGFuZCBkZW5zZSBsYXllcnMKICAgIAogICAgLSBUaGUgZmluYWwgbGF5ZXIgc2hvdWxkIGJlIGEgRGVuc2UgbGF5ZXIgd2l0aCB0aGUgbnVtYmVyIG9mIHVuaXRzIGFuZCAKICAgIGFjdGl2YXRpb24gZnVuY3Rpb24gdGhhdCBzdXBwb3J0cyBiaW5hcnkgY2xhc3NpZmljYXRpb24uCg==\"\n",
    "encoded_answer = encoded_answer.encode('ascii')\n",
    "answer = base64.b64decode(encoded_answer)\n",
    "answer = answer.decode('ascii')\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Felicitaciones por haber terminado la última tarea de este curso.**\n",
    "\n",
    "Has implementado con éxito una CNN para ayudarte en la tarea de clasificación de imágenes complejas. Buen trabajo.\n",
    "\n",
    "**Sigue así.**\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "**Congratulations on finishing the last assignment of this course!**\n",
    "\n",
    "You have successfully implemented a CNN to assist you in the classification task for complex images. Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
