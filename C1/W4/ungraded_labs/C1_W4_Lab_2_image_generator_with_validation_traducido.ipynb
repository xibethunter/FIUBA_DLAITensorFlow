{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W4/ungraded_labs/C1_W4_Lab_2_image_generator_with_validation_traducido.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB2cQUShkXNm"
   },
   "source": [
    "# Ungraded Lab: ImageDataGenerator con un conjunto de validación\n",
    "\n",
    "En este laboratorio, seguirá utilizando la clase `ImageDataGenerator` para preparar el conjunto de datos `Horses or Humans`. Esta vez, agregará un conjunto de validación para que también pueda medir el desempeño del modelo en datos que no ha visto.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "# Ungraded Lab: ImageDataGenerator with a Validation Set\n",
    "\n",
    "In this lab, you will continue using the `ImageDataGenerator` class to prepare the `Horses or Humans` dataset. This time, you will add a validation set so you can also measure how well the model performs on data it hasn't seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsO-u_3fySMd"
   },
   "source": [
    "**NOTA IMPORTANTE:** Este cuaderno está diseñado para ejecutarse como Colab. Ejecutarlo en su máquina local puede dar lugar a que algunos de los bloques de código arrojen errores.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running it on your local machine might result in some of the code blocks throwing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instale este paquete para utilizar la GPU de Colab para la formación\n",
    "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5FfBGV5yUjb"
   },
   "source": [
    "Ejecute los siguientes bloques de código para descargar los conjuntos de datos `caballo-o-humano.zip` y `validación-caballo-o-humano.zip` respectivamente.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Run the code blocks below to download the datasets `horse-or-human.zip` and `validation-horse-or-human.zip` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXZT2UsyIVe_"
   },
   "outputs": [],
   "source": [
    "# Descargar el conjunto de entrenamiento\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mLij6qde6Ox"
   },
   "outputs": [],
   "source": [
    "# Descargar el conjunto de validación\n",
    "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brUxyTpYZHy"
   },
   "source": [
    "Luego descomprime ambos archivos.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Then unzip both archives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLy3pthUS0D2"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Descomprimir el conjunto de entrenamiento\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "\n",
    "# Descomprimir conjunto de validación\n",
    "local_zip = './validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./validation-horse-or-human')\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-qUPyfO7Qr8"
   },
   "source": [
    "Al igual que en el laboratorio anterior, definirá los directorios que contienen sus imágenes. Esta vez, incluirá los que tienen datos de validación.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Similar to the previous lab, you will define the directories containing your images. This time, you will include those with validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NR_M9nWN-K8B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directorio con fotos de caballos de entrenamiento\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "# Directorio con fotos de humanos en entrenamiento\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "# Directorio con imágenes de caballos de validación\n",
    "validation_horse_dir = os.path.join('./validation-horse-or-human/horses')\n",
    "\n",
    "# Directorio con fotos de humanos de validación\n",
    "validation_human_dir = os.path.join('./validation-horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuBYtA_Zd8_T"
   },
   "source": [
    "Ahora vea cómo son los nombres de los archivos en estos directorios:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Now see what the filenames look like in these directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PIP1rkmeAYS"
   },
   "outputs": [],
   "source": [
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(f'TRAIN SET HORSES: {train_horse_names[:10]}')\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(f'TRAIN SET HUMANS: {train_human_names[:10]}')\n",
    "\n",
    "validation_horse_names = os.listdir(validation_horse_dir)\n",
    "print(f'VAL SET HORSES: {validation_horse_names[:10]}')\n",
    "\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(f'VAL SET HUMANS: {validation_human_names[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlqN5KbafhLI"
   },
   "source": [
    "Puede averiguar el número total de imágenes de caballos y humanos en los directorios:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "You can find out the total number of horse and human images in the directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4XHh2xSfgie"
   },
   "outputs": [],
   "source": [
    "print(f'total training horse images: {len(os.listdir(train_horse_dir))}')\n",
    "print(f'total training human images: {len(os.listdir(train_human_dir))}')\n",
    "print(f'total validation horse images: {len(os.listdir(validation_horse_dir))}')\n",
    "print(f'total validation human images: {len(os.listdir(validation_human_dir))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3WZABE9eX-8"
   },
   "source": [
    "Ahora echa un vistazo a algunas imágenes para tener una mejor idea de su aspecto. Primero, configura los parámetros de `matplotlib`:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Now take a look at a few pictures to get a better sense of what they look like. First, configure the `matplotlib` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2_Q0-_5UAv-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parámetros para nuestro gráfico; vamos a dar salida a las imágenes en una configuración 4x4\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Índice para iterar sobre las imágenes\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTvHzGCxXkqp"
   },
   "source": [
    "Ahora, muestre un lote de 8 imágenes de caballos y 8 de humanos. Puede volver a ejecutar la celda para ver un nuevo lote cada vez:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "Now, display a batch of 8 horse and 8 human pictures. You can rerun the cell to see a fresh batch each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpr8GxjOU8in"
   },
   "outputs": [],
   "source": [
    "# Configurar matplotlib fig, y dimensionarlo para que quepa en 4x4 fotos\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_dir, fname) \n",
    "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_dir, fname) \n",
    "                for fname in train_human_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
    "    # Configurar el subplot; los índices del subplot comienzan en 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # No mostrar los ejes (ni las líneas de la cuadrícula)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oqBkNBJmtUv"
   },
   "source": [
    "## Construir un pequeño modelo desde cero\n",
    "\n",
    "Definirás la misma arquitectura del modelo que antes:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Building a Small Model from Scratch\n",
    "\n",
    "You will define the same model architecture as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvfZg3LQbD-5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Tenga en cuenta la forma de entrada es el tamaño deseado de la imagen 300x300 con 3 bytes de color\n",
    "    # Esta es la primera convolución\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # La segunda convolución\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # La tercer convolución\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # La cuarta convolución\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # La quinta convolución\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Aplanar los resultados para alimentar una DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Capa oculta de 512 neuronas\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Sólo 1 neurona de salida. Contendrá un valor de 0-1 \n",
    "    # donde 0 para una clase ('caballos') y 1 para la otra ('humanos')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9EaFDP5srBa"
   },
   "source": [
    "Puede revisar la arquitectura de la red y las formas de salida con `model.summary()`.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "You can review the network architecture and the output shapes with `model.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZKj8392nbgP"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEkKSpZlvJXA"
   },
   "source": [
    "También utilizará la misma configuración de compilación que antes:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "You will also use the same compile settings as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DHWhFP_uhq3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn9m9D3UimHM"
   },
   "source": [
    "### Preprocesamiento de datos\n",
    "\n",
    "Ahora configurará los generadores de datos. En su mayor parte será lo mismo que la última vez, pero observe el código adicional para preparar también los datos de validación. Tendrá que ser instanciado por separado y también escalado para tener `[0,1]` rango de valores de píxeles.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "Now you will setup the data generators. It will mostly be the same as last time but notice the additional code to also prepare the validation data. It will need to be instantiated separately and also scaled to have `[0,1]` range of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClebU9NJg99G"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Todas las imágenes serán reescaladas por 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flujo de imágenes de entrenamiento en lotes de 128 utilizando el generador train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # Este es el directorio de origen para las imágenes de entrenamiento\n",
    "        target_size=(300, 300),  # Todas las imágenes serán redimensionadas a 300x300\n",
    "        batch_size=128,\n",
    "        # Como se utiliza la pérdida binaria_crossentropy, se necesitan etiquetas binarias\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flujo de imágenes de validación en lotes de 128 utilizando el generador validation_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './validation-horse-or-human/',  # Este es el directorio de origen para las imágenes de validación\n",
    "        target_size=(300, 300),  # Todas las imágenes se redimensionarán a 300x300\n",
    "        batch_size=32,\n",
    "        # Como se utiliza la pérdida binaria_crossentropy, se necesitan etiquetas binarias\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu3Jdwkjwax4"
   },
   "source": [
    "### Entrenamiento\n",
    "Ahora entrena el modelo durante 15 épocas. Aquí, pasarás parámetros para `validation_data` y `validation_steps`. Con estos, usted notará salidas adicionales en las declaraciones de impresión: `val_loss` y `val_accuracy`. Observe que a medida que entrena con más épocas, su precisión de entrenamiento puede aumentar pero su precisión de validación disminuye. Esto puede ser un signo de sobreajuste y necesitas evitar que tu modelo llegue a este punto.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "### Training\n",
    "Now train the model for 15 epochs. Here, you will pass parameters for `validation_data` and `validation_steps`. With these, you will notice additional outputs in the print statements: `val_loss` and `val_accuracy`. Notice that as you train with more epochs, your training accuracy might go up but your validation accuracy goes down. This can be a sign of overfitting and you need to prevent your model from reaching this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fb1_lgobv81m"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6vSHzPR2ghH"
   },
   "source": [
    "### Predicción del modelo\n",
    "\n",
    "Ahora eche un vistazo a la ejecución de una predicción utilizando el modelo. Este código le permitirá elegir 1 o más archivos de su sistema de archivos, cargarlos y ejecutarlos a través del modelo, dando una indicación de si el objeto es un caballo o un humano.\n",
    "\n",
    "**Nota importante:** Debido a algunos problemas de compatibilidad, el siguiente bloque de código dará lugar a un error después de seleccionar las imágenes a cargar si está ejecutando este cuaderno como un `Colab` en el navegador `Safari`. Para todos los demás navegadores, continúe con el siguiente bloque de código e ignore el que le sigue.\n",
    "\n",
    "Para los usuarios de Safari: por favor, comente u omita el bloque de código de abajo, descomente el siguiente bloque de código y ejecútelo.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "### Model Prediction\n",
    "\n",
    "Now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, upload them, and run them through the model, giving an indication of whether the object is a horse or a human.\n",
    "\n",
    "**Important Note:** Due to some compatibility issues, the following code block will result in an error after you select the images(s) to upload if you are running this notebook as a `Colab` on the `Safari` browser. For all other browsers, continue with the next code block and ignore the next one after it.\n",
    "\n",
    "_For Safari users: please comment out or skip the code block below, uncomment the next code block and run it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoWp43WxJDNT"
   },
   "outputs": [],
   "source": [
    "## BLOQUE DE CÓDIGO PARA NAVEGADORES QUE NO SEAN SAFARI\n",
    "## USUARIOS DE SAFARI: POR FAVOR, OMITA ESTE BLOQUE Y EJECUTE EL SIGUIENTE EN SU LUGAR\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "    else:\n",
    "    print(fn + \" is a horse\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJV8rdWU0NlM"
   },
   "source": [
    "Los usuarios de `Safari` tendrán que cargar las imágenes manualmente en su espacio de trabajo. Por favor, siga las instrucciones, descomente el bloque de código de abajo y ejecútelo.\n",
    "\n",
    "Instrucciones para subir imágenes manualmente en un Colab:\n",
    "\n",
    "1. Seleccione el icono de la `carpeta` en la `barra de menú` de la izquierda.\n",
    "2. Haga clic en la `carpeta con una flecha apuntando hacia arriba` llamada `..`.\n",
    "3. Haga clic en la `carpeta` llamada `tmp`.\n",
    "4. Dentro de la carpeta `tmp`, `crea una nueva carpeta` llamada `imágenes`. Verás la opción `Nueva carpeta` haciendo clic en el botón de menú de los `3 puntos verticales` junto a la carpeta `tmp`.\n",
    "5. Dentro de la nueva carpeta `imágenes`, sube una(s) imagen(es) de tu elección, preferiblemente de un caballo o de un humano. Arrastra y suelta la(s) imagen(es) encima de la carpeta `images`.\n",
    "6. Descomente y ejecute el bloque de código que aparece a continuación. \n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "`Safari` users will need to upload the images(s) manually in their workspace. Please follow the instructions, uncomment the code block below and run it.\n",
    "\n",
    "Instructions on how to upload image(s) manually in a Colab:\n",
    "\n",
    "1. Select the `folder` icon on the left `menu bar`.\n",
    "2. Click on the `folder with an arrow pointing upwards` named `..`\n",
    "3. Click on the `folder` named `tmp`.\n",
    "4. Inside of the `tmp` folder, `create a new folder` called `images`. You'll see the `New folder` option by clicking the `3 vertical dots` menu button next to the `tmp` folder.\n",
    "5. Inside of the new `images` folder, upload an image(s) of your choice, preferably of either a horse or a human. Drag and drop the images(s) on top of the `images` folder.\n",
    "6. Uncomment and run the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyIcglKE0MpY"
   },
   "outputs": [],
   "source": [
    "# # CODE BLOCK FOR SAFARI USERS\n",
    "\n",
    "# import numpy as np\n",
    "# from keras.preprocessing import image\n",
    "# import os\n",
    "\n",
    "# images = os.listdir(\"/tmp/images\")\n",
    "\n",
    "# print(images)\n",
    "\n",
    "# for i in images:\n",
    "#  print()\n",
    "#  # predicting images\n",
    "#  path = '/tmp/images/' + i\n",
    "#  img = image.load_img(path, target_size=(300, 300))\n",
    "#  x = image.img_to_array(img)\n",
    "#  x /= 255\n",
    "#  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#  images = np.vstack([x])\n",
    "#  classes = model.predict(images, batch_size=10)\n",
    "#  print(classes[0])\n",
    "#  if classes[0]>0.5:\n",
    "#    print(i + \" is a human\")\n",
    "#  else:\n",
    "#    print(i + \" is a horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8EHQyWGDvWz"
   },
   "source": [
    "### Visualización de representaciones intermedias\n",
    "\n",
    "Al igual que antes, se puede trazar cómo se transforman las características a medida que pasa por cada capa.\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "### Visualizing Intermediate Representations\n",
    "\n",
    "As before, you can plot how the features are transformed as it goes through each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5tES8rXFjux"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Definir un nuevo modelo que tomará una imagen como entrada, y emitirá\n",
    "# representaciones intermedias para todas las capas del modelo anterior después de\n",
    "# la primera.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "# Prepara una imagen de entrada aleatoria del conjunto de entrenamiento.\n",
    "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(300, 300))  # esta es una imagen PIL\n",
    "x = img_to_array(img)  # matriz Numpy con forma (300, 300, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Matriz Numpy con forma (1, 300, 300, 3)\n",
    "\n",
    "# Escala por  1/255\n",
    "x /= 255\n",
    "\n",
    "# Pasar la imagen por la red, obteniendo así todas\n",
    "# representaciones intermedias de esta imagen.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# Estos son los nombres de las capas, por lo que puede tenerlos como parte de la trama\n",
    "layer_names = [layer.name for layer in model.layers[1:]]\n",
    "\n",
    "# Visualizar las representaciones\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "\n",
    "    # Sólo se hace esto para las capas conv / maxpool, no para las capas totalmente conectadas\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "\n",
    "    # El mapa de características tiene forma (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "\n",
    "    # Mosaico de las imágenes en esta matriz\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "        x = feature_map[0, :, :, i]\n",
    "        x -= x.mean()\n",
    "        x /= x.std()\n",
    "        x *= 64\n",
    "        x += 128\n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "        # Colocar cada filtro en esta gran cuadrícula horizontal\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "    \n",
    "    # Mostrar la grilla\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4IBgYCYooGD"
   },
   "source": [
    "## Limpiar\n",
    "\n",
    "Antes de ejecutar el siguiente ejercicio, ejecute la siguiente celda para terminar el kernel y liberar recursos de memoria:\n",
    "\n",
    "<details><summary><font size=\"2\" color=\"darkblue\"><b> Texto Original </b></font></summary>\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "Before running the next exercise, run the following cell to terminate the kernel and free memory resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "651IgjLyo-Jx"
   },
   "outputs": [],
   "source": [
    "# import os, signal\n",
    "# os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W4_Lab_2_image_generator_with_validation.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W4/ungraded_labs/C1_W4_Lab_2_image_generator_with_validation.ipynb",
     "timestamp": 1639109465068
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
