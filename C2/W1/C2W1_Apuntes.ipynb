{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TENSORFLOW DEVELOPER PROFESSIONAL CERTIFICATE**\n",
    "# Curso 2: Convolutional Neural Networks in TensorFlow\n",
    "# Semana 1: Exploring a Larger Dataset\n",
    "\n",
    "*Esta notebook plasma los apuntes traducidos al español del Curso dicatado por [DeepLearning.AI](https://www.deeplearning.ai/courses/), por lo que puede encontrar errores. Las figuras y ecuaciones se han obtenido/adaptado directamente de las diapositivas utilizadas en el curso. Todo el mérito es de los instructores. Simplemente espero que los apuntes sirvan como material de estudio complementario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING A LARGER DATASET\n",
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction, A conversation with Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer curso, aprendiste a usar TensorFlow para implementar una red neuronal básica, yendo hasta la Red Neural Convolucional básica. En este segundo curso, vas mucho más allá. \n",
    "\n",
    "En la primera semana, usted toma las ideas que ha aprendido, y las aplica a un conjunto de datos mucho más grande de gatos frente a perros en Kaggle. Tomamos el conjunto completo de datos de Kaggle de 25.000 gatos contra perros. En el último módulo, miramos caballos y humanos, que eran alrededor de 1.000 imágenes. Así que queremos echar un vistazo a lo que es entrenar un conjunto de datos mucho más grande, y eso fue como un desafío de ciencia de datos, no hace mucho tiempo. Ahora, vamos a estar aprendiendo eso aquí, que creo que es realmente genial. De hecho, tenemos ideas sustancialmente similares a sus objetivos anteriores, y aplicarlas a conjuntos de datos mucho más grandes, y esperamos obtener grandes resultados. Sí, esperamos buenos resultados. Veamos qué obtienen los estudiantes mientras hacen algunas de las tareas con él también. Una de las cosas con las que trabajar con un conjunto de datos más grande, entonces ayuda es el exceso de ajuste. Por lo tanto, con un conjunto de datos más pequeño, corre un gran riesgo de sobreajuste; con un conjunto de datos más grande, entonces tiene menos riesgo de sobreajuste, pero el sobreajuste aún puede suceder. Bastante genial. \n",
    "\n",
    "Luego, en la semana 2, aprenderás otro método para lidiar con el sobreajuste, que es que TensorFlow proporciona herramientas muy fáciles de usar para el aumento de datos , donde puedes, por ejemplo, tomar una foto de un gato, y si tomas la imagen de espejo de la imagen de un gato, todavía se ve Como un gato. Entonces, ¿por qué no hacer eso, y tirar eso en el set de entrenamiento? Exactamente. O, por ejemplo, es posible que sólo tenga imágenes verticales de gatos, pero si el gato está acostado, o está de lado, entonces una de las cosas que puede hacer es rotar la imagen. Así que es como parte del aumento de la imagen, es rotación, sesgar, voltear, moverlo alrededor del marco, ese tipo de cosas. Una de las cosas que encuentro realmente limpio al respecto, es particularmente si estás usando un conjunto de datos público grande, es entonces fluye todas las imágenes directamente, y el aumento ocurre a medida que fluye. Así que no estás editando las imágenes directamente. No va a cambiar el conjunto de datos. Todo sucede en la memoria. ¿Todo esto se hace como parte de la generación de imágenes de TensorFlow [inaudible]? Exactamente. Que lo sabrán en la segunda semana. \n",
    "\n",
    "También una de las otras estrategias, por supuesto para evitar el sobreajuste, es utilizar modelos existentes y tener aprendizaje de transferencia. Sí. Así que no creo que nadie tenga tantos datos como desee, por los problemas que realmente nos importan. Así que Transfer Learning, te permite descargar la red neuronal, que tal vez alguien más ha entrenado en un millón de imágenes, o incluso más de un millón de imágenes. Así que tome una red inicial, que alguien más haya entrenado, descargue esos parámetros y use eso para iniciar su propio proceso de aprendizaje, tal vez con un conjunto de datos más pequeño. Exactamente. Eso ha sido capaz de detectar las entidades que es posible que no haya podido detectar en su conjunto de datos, así que ¿por qué no ser capaz de aprovechar eso y acelerar el entrenamiento suyo? Me parece particularmente interesante a medida que avanzas. Que ser capaz de construir a partir del trabajo de otras personas, la naturaleza abierta de la comunidad de IA, me parece realmente emocionante y eso le permite realmente aprovechar eso y ser parte de la comunidad. De pie sobre los hombros de los gigantes. Utilizo el aprendizaje de transferencia todo el tiempo, por lo que TensorFlow te permite hacerlo fácilmente [inaudible] de código abierto. \n",
    "\n",
    "Luego, finalmente, en la cuarta semana, el aprendizaje de multidifusión. En lugar de hacer dos clases, como caballos versos humanos, o gatos versos perros, ¿qué pasa si usted tiene más de dos clases, como la clase cinco roca , papel, tijeras, que serían tres clases, o el inicio sería 1.000 clases. Así que las técnicas de pasar de dos a más de dos, ya sean tres o mil, son muy similares. Así que vamos a ver esas técnicas y vamos a ver el código para eso. Así que tenemos un ejemplo de piedra, papel, tijeras, del que vas a ser capaz de construir. Así que en este segundo curso, tomas lo que aprendiste en el primer curso, pero vas mucho más profundo. Una última cosa divertida, Lawrence había visto esta taza de café en IA para todos en el curso, y me pidió que la trajera. Me encanta ese curso, así que muchas gracias. Es un curso genial, porque tiene todo para las personas que están comenzando; incluso para las personas que no son técnicas, hasta expertos. Así que gracias por la taza, pero está bien si digo que también veo un coche deportivo en el curso, ¿me traerías eso? No tengo uno de esos para traerte. Así que estoy muy emocionado con este curso. Por favor, siga adelante y sumérjase en el primero de los materiales para la semana 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where to find the notebooks for this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los cuadernos de este curso se pueden ejecutar en Google Colab o en Coursera Labs. No necesitas un entorno local configurado para seguir los ejercicios de codificación. Puedes simplemente hacer clic en la insignia de Abrir en Colab en la parte superior de los laboratorios no calificados, mientras que para las tareas, serás llevado automáticamente a Coursera Labs. \n",
    "\n",
    "Sin embargo, si quieres ejecutarlos en tu máquina local, los laboratorios sin calificar y las tareas de cada semana se pueden encontrar en este [repositorio de Github](https://github.com/https-deeplearning-ai/tensorflow-1-public) bajo la carpeta C2. Si ya tienes git instalado en tu ordenador, puedes clonarlo con este comando\n",
    "\n",
    "git clone https://github.com/https-deeplearning-ai/tensorflow-1-public\n",
    "\n",
    "Si no es así, sigue las guías aquí para instalar git en tu sistema operativo. Una vez que hayas clonado el repo, puedes hacer un git pull de vez en cuando para asegurarte de que obtienes las últimas actualizaciones de los cuadernos.\n",
    "\n",
    "Necesitarás estos paquetes si vas a ejecutar los cuadernos localmente:\n",
    "\n",
    "```Python\n",
    "    tensorflow==2.7.0\n",
    "    scikit-learn==1.0.1\n",
    "    pandas==1.1.5\n",
    "    matplotlib==3.2.2\n",
    "    seaborn==0.11.2\n",
    "```\n",
    "\n",
    "> **Para ver las colab en español se puede visitar o clonar este [repositorio Hithub](https://github.com/IngCarlaPezzone/tensorflow-1-public.git).**\n",
    "> Este es el repositorio forkeado del curso (Sep/2022) al que le fui agregando copia de cada notebook con la traducción al español. Todos los creditos son a los autores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A conversation with Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué se necesita para descargar un conjunto de datos público de Internet, como gatos versos perros, y conseguir una red neuronal para trabajar en él? Los datos son desordenados, a veces encuentras cosas sorprendentes como imágenes de personas que sostienen gatos o gatos múltiples o cosas sorprendentes en los datos. \n",
    "\n",
    "En esta semana, usted puede practicar con el uso de TensorFlow para lidiar con todos estos problemas. Sí, y es como, así que incluso por ejemplo, es posible que tenga algunos archivos de longitud cero y que podrían estar corruptos como resultado. Así que es como usar tus habilidades de Python, usar tus habilidades de TensorFlow para poder filtrarlas. Construyendo una red convolucional para poder detectar cosas como usted mencionó, una persona sosteniéndola. Así que eso es algunas de las cosas que haremos esta semana, es usando, y sigue siendo un conjunto de datos muy limpio que estamos usando con gatos versus perros, pero vas a golpear algunos de esos problemas. Creo que aprenderás las habilidades que necesitas para poder lidiar con otros conjuntos de datos que pueden no ser tan limpios como este. Sí. \n",
    "\n",
    "A veces la gente piensa que la IA es gente como Lawrence y yo sentada frente a una pizarra blanca tal vez un jardín zen afuera, hablando del futuro de la humanidad. La realidad es que hay una gran cantidad de limpieza de datos, y tener grandes herramientas para ayudar con esa limpieza de datos hace que nuestro flujo de trabajo sea mucho más eficiente. Definitivamente. Así que en esta semana, puedes practicar todo eso, así como entrenar a una red neuronal bastante genial para clasificar gatos frente a perros. Por favor, sumergirse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cats vs dogs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente vídeo, verás el famoso conjunto de datos Kaggle Dogs v Cats.\n",
    "\n",
    "Originalmente se trataba de un reto de construcción de un clasificador dirigido a los mejores profesionales del aprendizaje automático y la IA del mundo, pero la tecnología ha avanzado tan rápidamente que verás cómo puedes hacerlo en tan sólo unos minutos con algo de programación sencilla de redes neuronales convolucionales.\n",
    "\n",
    "También es un buen ejercicio para ver un conjunto de datos más grande, descargarlo y prepararlo para el entrenamiento, así como manejar algo de preprocesamiento de datos. Incluso los datos que han sido cuidadosamente curados para ti pueden tener errores - ¡como notarás con algunas imágenes corruptas!\n",
    "\n",
    "Además, es posible que notes algunas advertencias sobre datos EXIF faltantes o corruptos mientras las imágenes se cargan en el modelo para el entrenamiento. No se preocupe por esto - ¡no afectará a su modelo! :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with the cats vs. dogs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos pasado del conjunto de datos de moda donde las imágenes eran pequeñas y se centraban en el tema, a una nueva situación en la que teníamos imágenes de caballos y humanos y poses de acción. Utilizamos convoluciones para ayudarnos a identificar entidades en la imagen independientemente de su ubicación. \n",
    "\n",
    "Esta es una buena guía para resolver algunos problemas comunes de ciencia de datos en lugares como Kaggle. A continuación veremos una antigua competencia en la que se le animó a construir un clasificador para determinar gatos frente a perros. Si no estás familiarizado con Kaggle, es donde los desafíos de ML se publican a menudo con premios. Gatos contra perros era un famoso de hace unos años. \n",
    "\n",
    "Las técnicas que acabas de aprender pueden aplicarse a ese problema. Así que recapitulemos algunos de los conceptos. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_03.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Una de las cosas buenas con TensorFlow y Keras es que si pones tus imágenes en subdirectorios con nombre, una imagen generada las etiquetará automáticamente por ti. Así que el conjunto de datos de gatos y perros en realidad podría hacer eso y ya tiene una ventaja masiva en la construcción del clasificador. A continuación, puede subdividir eso en un conjunto de entrenamiento y un conjunto de validación. \n",
    "\n",
    "A continuación, puede utilizar generadores de imágenes que se designan en esas carpetas. \n",
    "\n",
    "``` python\n",
    "from tensorflow.keras.preprocessing.image\n",
    "import ImageDataGenerator\n",
    "```\n",
    "\n",
    "Para utilizar un generador de imágenes, debe crear una instancia de uno. Si los datos aún no están normalizados, puede hacerlo con el parámetro de reescala. \n",
    "\n",
    "``` python\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "A continuación, llame al flujo desde el directorio para obtener un objeto generador. Para el conjunto de datos de formación, señalará el directorio de formación y, a continuación, especificará el tamaño de destino. En este caso, las imágenes son de todas las formas y tamaños. Así que los redimensionaremos a 150 por 150 sobre la marcha. Estableceremos los tamaños de lote en 20. Hay 2.000 imágenes, así que usaremos 100 lotes de 20 cada uno. Debido a que hay dos clases que queremos clasificar para su todavía permanece como un modo de clase binaria. \n",
    "\n",
    "``` python\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "```\n",
    "\n",
    "Del mismo modo, para la validación, configuramos un generador y apuntamos al directorio de validación. \n",
    "\n",
    "``` python\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "```\n",
    "\n",
    "Podemos explorar las convoluciones y la agrupación (Pooling) y el viaje de la imagen a través de ellas. Es muy similar a lo que viste con los caballos y los humanos. Tiene tres conjuntos de convoluciones seguidas de agrupación. Por supuesto, la imagen es de 150 por 150. Del mismo modo, hay una sola neurona con una activación sigmoide en la salida. \n",
    "\n",
    "``` python\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', \n",
    "                          input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "El resumen de las capas es muy similar al anterior, pero tenga en cuenta que el tamaño cambia. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_18.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Comenzamos con 150 por 150. Así que la circunvolución reduce eso a 148 por 148. A partir de ahí, iremos hasta que terminemos con 17 por 17 que alimentemos en las capas densas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación es como antes. Ahora recuerde que puede ajustar la tasa de aprendizaje ajustando el parámetro lr. \n",
    "\n",
    "``` python\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.001),\n",
    "             metrics=['acc'])\n",
    "```\n",
    "\n",
    "Así que ahora para entrenar, y podemos llamar `model.fit` generador y pasarlo el generador de entrenamiento y el generador de validación. \n",
    "\n",
    "``` python\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    step_per_epoch=100,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    "    verbose=2)\n",
    "```\n",
    "\n",
    "Eso es todo. Como puedes ver, es muy similar a lo que construiste para caballos contra humanos. Así que vamos a verlo en acción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the notebook (Lab 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bueno, si, ese también jajaAhora que hemos hablado de cómo se extiende a los datos del mundo real utilizando el conjunto de datos Cats vs Dogs, vamos a entrar en un cuaderno que muestra cómo hacer el reto por ti mismo. En el siguiente vídeo, verás un screencast de este cuaderno en acción. A continuación, podrás probarlo por ti mismo.\n",
    "\n",
    "> El Laboratorio en español se pueden encontrar\n",
    "> [aqui](https://github.com/IngCarlaPezzone/tensorflow-1-public/blob/main/C2/W1/ungraded_lab/C2_W1_Lab_1_cats_vs_dogs_Traducida.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working through the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haremos es descargar el conjunto de imágenes. Se almacenan como un archivo zip que contiene 3.000 imágenes, 2.000 de las cuales usaremos para entrenamiento y 1.000 para pruebas. \n",
    "\n",
    "Una vez descargados, necesitará acceder al sistema operativo subyacente de la máquina virtual en la que se ejecuta este Colab. Esto está disponible en el espacio de nombres del sistema operativo. \n",
    "\n",
    "Este código descomprimirá los datos de perros y gatos que acabas de descargar en el directorio /tmp. \n",
    "\n",
    "```python \n",
    "import zipfile\n",
    "\n",
    "# Unzip the archive\n",
    "local_zip = './cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "\n",
    "zip_ref.close()\n",
    "```\n",
    "\n",
    "Allí, los subdirectorios se volverán a crear, porque están almacenados que estaban en el archivo zip. \n",
    "\n",
    "Lo siguiente es que establezcamos nuestros directorios como variables, para que podamos apuntar los generadores hacia ellos. \n",
    "\n",
    "```python \n",
    "import os\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "```\n",
    "\n",
    "Ahora, que tenemos los directorios como variables, podemos pasarlos al `os.list` aquí para tomar los archivos de esos directorios, y cargarlos en las listas de Python. \n",
    "\n",
    "```python\n",
    "train_cat_fnames = os.listdir( train_cats_dir )\n",
    "train_dog_fnames = os.listdir( train_dogs_dir )\n",
    "\n",
    "print(train_cat_fnames[:10])\n",
    "print(train_dog_fnames[:10])\n",
    "```\n",
    "\n",
    "\n",
    "Podemos ver que hay una lista de nombres de archivo como cat253.jpg, etc. En la pestaña de archivos, también podemos inspeccionar el sistema de archivos y en TMP, podemos ver nuestra carpeta gatos versus perros, dentro de la cual tenemos subdirectorios de entrenamiento y validación, que contienen gatos y perros directorios. Las imágenes, por supuesto, se almacenan allí. Si contamos las imágenes en cada directorio, podemos estar seguros de que tenemos las cantidades correctas de imágenes. \n",
    "\n",
    "```python\n",
    "print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\n",
    "print('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n",
    "\n",
    "print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\n",
    "print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\n",
    "\n",
    "```\n",
    "\n",
    "Como podemos ver, tenemos mil de cada animal en Entrenamiento y 500 de cada uno en Pruebas para un total de 3000. \n",
    "\n",
    "A continuación, podemos visualizar algunos de los datos, para que podamos ver lo diverso que es. Este código establecería un matplotlib que es una biblioteca de Python para dibujar gráficos. Este código recogerá algunos gatos y perros al azar y los dibujará en una cuadrícula. Una vez dibujado, podemos ver que hay mucha diversidad en estas imágenes. Hay diferentes colores de animales, hay una ubicación diferente dentro de la imagen, e incluso a veces hay varios elementos en la imagen, como la dama aquí sosteniendo a un gato. Entonces podemos volver a ejecutarlo para ver un poco más. Esta imagen que contiene varios gatos es particularmente desafiante. \n",
    "\n",
    "Está bien. Ahora, construyamos nuestra red neuronal. Importaremos TensorFlow, y luego definiremos nuestro modelo. Imprimiremos el resumen, y aquí puede ver la forma de salida de cómo la imagen pasó a través de las capas, y reducir gradualmente su tamaño a través de la convolución y agrupación. \n",
    "\n",
    "Aquí, es donde compilamos nuestro modelo, definiendo la función de pérdida y el optimizador. Aquí, es donde configuramos los dos generadores, señalándolos a los subdirectorios de capacitación y validación. Estos contienen subdirectorios propios, cada uno con gatos y perros. Cuando lo ejecute, verás la copia impresa. \n",
    "\n",
    "Encontró 2.000 imágenes en dos clases, y ese es el entrenamiento, y 1.000 imágenes en dos clases, esa es la prueba. Ahora, podemos hacer el entrenamiento. \n",
    "\n",
    "Volveremos a usar `model.fit`. Ahora, puedes ver que han pasado. Ahora, comenzaremos el entrenamiento y lo veremos progresar. Debería tomar de 3 a 3,5 minutos. Cuando está hecho, se puede ver que la precisión es de aproximadamente 73% y no está mal. No es genial, pero no está mal. \n",
    "\n",
    "Está bien. Así que echemos un vistazo a cómo el modelo predice en algunas imágenes. Así que voy a elegir estas cinco imágenes de mi disco duro y subirlas. Una vez que se suben, puedes ver que el clasificador me da una predicción sobre cada uno. Así que vamos a comparar ahora. Podemos ver que la primera está obviamente equivocada, pero ahora veamos cada imagen para ver si podemos comparar los resultados. Este primero es realmente impresionante y como se puede ver, el perro está en una parte muy pequeña de la imagen y hay muchas otras características como árboles, montañas, cielos y lagos, y el perro también tiene su cara de vuelta, pero el clasificador todavía lo tiene bien. Este es obviamente un perro, pero de nuevo está parcialmente oscurecido. No puedes ver el cuerpo. Es sólo una masa blanca y la cara, aunque pronunciada, también está oculta entre la piel, pero lo hizo bien. Este es un poco más obvio, pero también es un perro muy diferente que el anterior. Los ojos, la nariz y la boca son todos parte de un parche oscuro, pero la red neuronal todavía reconocen al perro. Este también es muy impresionante. Hay dos gatos en la imagen y uno está en su mayoría oculto, pero eso no confundió el modelo que reconoció correctamente al gato aquí. Aunque por extraño que parezca, este es el que el modelo se equivocó. Tal vez es porque solo podemos ver un ojo, o tal vez las ramas fuertemente definidas a la izquierda confunden el modelo. \n",
    "\n",
    "Así que eche un vistazo, piense en lo que haría para revisar estos libros de trabajo en este momento y divertirse con él. Encuentra algunas imágenes de gatos y perros y súbelas al cuaderno y consigue que las clasifique, luego ve si puedes encontrar una que esperarías que sea fácil que la predicción se equivoque. Una vez que lo hayas hecho, comprueba si puedes editar esa imagen de una manera que funcione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you'll see next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, viste un screencast del cuaderno que muestra cómo construir un clasificador para Gatos vs Perros. Viste cómo, en algunos casos, no clasificó correctamente un gato, y te pedimos que intentaras averiguar cómo podrías solucionarlo. En el siguiente vídeo, verás una solución a esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing through cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Encontraste una solución? Bueno, por supuesto que la tuya puede ser diferente a la mía pero déjame mostrarte lo que hice en el caso del gato que mi modelo pensaba era un perro. \n",
    "\n",
    "Así que volvamos al cuaderno, y ejecutaremos el código. Subiré esta imagen para ver cómo se clasifica. Es un recorte de gatos, y he aquí, se clasifica como un gato. Vamos a abrirlo, y compararlo con la imagen original, y veremos que sólo recortando pude conseguir que cambiara su clasificación. Debe haber habido algo en la imagen sin recortar que coincida con las características de un perro. Pensé que era un experimento muy interesante, ¿no? \n",
    "\n",
    "Ahora, ¿qué crees que el impacto de los recortes podría haber tenido en el entrenamiento? ¿Habría entrenado el modelo para demostrar que este era un gato mejor que una imagen sin recortar. Eso es algo para pensar, y algo para explorar en la siguiente lección, pero primero volvamos al libro de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the effect of the convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, en el video anterior echaste un vistazo a un cuaderno que entrenaba una red neuronal convolucional que clasificaba gatos contra perros. Ahora echemos un vistazo a cómo funcionó eso.\n",
    "\n",
    "Volvamos al cuaderno y echemos un vistazo al código que grafica las salidas de las convoluciones en capas de MaxPooling. La clave para esto es entender la API `model.layers`, que le permite encontrar las salidas e iterar a través de ellas, creando un modelo de visualización para cada una.\n",
    "\n",
    "Luego podemos cargar una imagen aleatoria en una matriz y pasarla al método de predicción del modelo de visualización.\n",
    "\n",
    "La variable a seguir es `display_grid` que se puede construir a partir de x que se lee como un mapa de características y se procesa un poco para la visibilidad en el bucle central.\n",
    "\n",
    "A continuación, renderizaremos cada una de las circunvoluciones de la imagen , además de su agrupación, luego otra convolución, etc.\n",
    "\n",
    "Puede ver imágenes como la nariz del perro siendo resaltada en muchas de las imágenes de la izquierda.\n",
    "\n",
    "Luego podemos ejecutarlo de nuevo para obtener otra imagen aleatoria. Y aunque a primera vista esto parece ser una rana, si miras de cerca es un gato siamés con una cabeza oscura y patas oscuras hacia la derecha del marco. Es difícil ver si alguna de las circunvoluciones bloquea una entidad. Excepto tal vez la cola vertical sinónimo del gato, podemos ver esa línea oscura vertical en una serie de las convoluciones.\n",
    "\n",
    "Y vamos a intentarlo una vez más. Podemos ver lo que es claramente un perro, y cómo las orejas del perro están representadas muy fuertemente. Características como este moviéndose a través de las convoluciones y siendo etiquetado como perro podría terminar siendo llamado algo así como un detector de orejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de irnos, echemos un vistazo rápido a trazar la historia de aprendizaje de este modelo. El objeto tiene valores de precisión y pérdida de entrenamiento , así como valores de exactitud de validación y pérdida de validación. \n",
    "\n",
    "Así que vamos a iterar sobre estos y trazar ellos. Ahora, si miras de cerca, no solo llamamos `model.fit`, dijimos que la `history = model.fit`. \n",
    "\n",
    "Así que ahora tenemos un objeto de historial que podemos consultar para los datos. Aquí puede ver que estoy usando el mismo objeto de historial, y estoy llamando a su propiedad de historial que pasa en `acc`, lo que me da la precisión del modelo. \n",
    "\n",
    "Cuando lo ejecuto y grafico la precisión de entrenamiento y validación, podemos ver que mi entrenamiento fue hacia 1, mientras que mi validación se niveló en rango de 0.7 a 0.75. Eso demuestra que mi modelo no es malo, pero realmente no gané nada después de dos épocas. \n",
    "\n",
    "Se ajusta muy bien a los datos de entrenamiento con los datos de validación necesarios. Estos resultados se confirman en la pérdida donde podemos ver que después de dos épocas, mi pérdida de entrenamiento bajó muy bien, pero mi pérdida de validación subió. Así que, mi modelo es del 75 por ciento exacto después de dos épocas, y realmente no necesito entrenar más. \n",
    "\n",
    "Recuerde también que acabamos de utilizar un subconjunto de los datos completos. El uso de todo el conjunto de datos probablemente arrojaría mejores resultados. Pero antes de hacerlo, veamos algunas otras opciones, y lo haremos en la siguiente lección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What have we seen so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final del último vídeo, has visto cómo explorar el historial de entrenamiento y has descubierto un fenómeno interesante: Aunque la precisión del conjunto de datos de entrenamiento fue muy alta, vimos que después de unas pocas épocas, el conjunto de validación se niveló. Esto es una clara señal de que estamos sobreajustando de nuevo. Usar más datos debería ayudar con esto, pero hay algunas otras técnicas que puedes usar con conjuntos de datos más pequeños también. Las veremos en la lección de la próxima semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Week 1 Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "¿Qué te da `flow_from_directory` en el ImageDataGenerator?\n",
    "\n",
    "- La capacidad de cargar fácilmente las imágenes para el entrenamiento\n",
    "- La capacidad de elegir el tamaño de las imágenes de entrenamiento\n",
    "- La capacidad de etiquetar automáticamente las imágenes en función de su nombre de directorio\n",
    "- Todo lo anterior\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Todo lo anterior.\n",
    "    \n",
    "Correcto. El método flow_from_directory toma la ruta de un directorio y genera lotes de datos aumentados.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Si mi Imagen tiene un tamaño de 150x150, y paso una Convolución 3x3 sobre ella, ¿qué tamaño tiene la imagen resultante?\n",
    "\n",
    "- 148x148\n",
    "- 153x153\n",
    "- 150x150\n",
    "- 450x450\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: 148x148 \n",
    "    \n",
    "Has acertado. Aplicando una convolución 3x3 se obtendría una imagen de 148x148.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "Si mis datos tienen un tamaño de 150x150, y utilizo Pooling de tamaño 2x2, ¿qué tamaño tendrá la imagen resultante?\n",
    "\n",
    "- 149x149\n",
    "- 300x300\n",
    "- 75x75\n",
    "- 148x148\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: 75x75.\n",
    "    \n",
    "Lo he hecho bien. Aplicando el pooling 2x2 se obtendría una imagen de 75x75\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 4 </b></font>\n",
    "\n",
    "Si quiero ver el historial de mi entrenamiento, ¿cómo puedo acceder a él?\n",
    "\n",
    "- Crea una variable 'history' y asígnala al retorno de `model.fit` o `model.fit_generator`\n",
    "- Descargar el modelo e inspeccionarlo\n",
    "- Pase el parámetro 'history=true' al `model.fit`\n",
    "- Utilizar un generador `model.fit`\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Crea una variable 'history' y asígnala al retorno de `model.fit` o `model.fit_generator` \n",
    "    \n",
    "Exacto. El atributo History.history es un registro de los valores de las pérdidas de entrenamiento y de los valores de las métricas en las sucesivas épocas.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 5 </b></font>\n",
    "\n",
    "¿Cómo se llama la API que permite inspeccionar el impacto de las convoluciones en las imágenes?\n",
    "\n",
    "- La API `model.layers`\n",
    "- La API `model.images`\n",
    "- La API `model.pools`\n",
    "- La API `model.convolutions`\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: La API `model.layers`.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 6 </b></font>\n",
    "\n",
    "Al explorar los gráficos, la pérdida se estabilizó en aproximadamente 0,75 después de 2 épocas, pero la precisión subió cerca de 1,0 después de 15 épocas. ¿Cuál es el significado de esto?\n",
    "\n",
    "- No hubo entrenamiento de puntos después de 2 épocas, ya que nos ajustamos demasiado a los datos de validación\n",
    "- No hubo ningún punto de entrenamiento después de 2 épocas, ya que nos ajustamos demasiado a los datos de entrenamiento\n",
    "- Un conjunto de entrenamiento más grande nos daría una mayor precisión en la validación\n",
    "- Un conjunto de validación más grande nos daría una mayor precisión de entrenamiento\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: No hubo ningún punto de entrenamiento después de 2 épocas, ya que nos ajustamos demasiado a los datos de entrenamiento.\n",
    "    \n",
    "Correcto Estos valores indican un sobreajuste de los datos de entrenamiento.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 7 </b></font>\n",
    "\n",
    "¿Por qué la precisión de validación es un mejor indicador del rendimiento del modelo que la precisión de entrenamiento?\n",
    "\n",
    "- No lo es, tienen el mismo valor\n",
    "- No hay relación entre ellas\n",
    "- La precisión de validación se basa en imágenes con las que no se ha entrenado el modelo y, por tanto, es un mejor indicador de cómo funcionará el modelo con nuevas imágenes.\n",
    "- El conjunto de datos de validación es más pequeño, y por tanto menos preciso para medir la precisión, por lo que su rendimiento no es tan importante\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: La precisión de validación se basa en imágenes con las que no se ha entrenado el modelo y, por tanto, es un mejor indicador de cómo funcionará el modelo con nuevas imágenes.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 8 </b></font>\n",
    "\n",
    "¿Por qué es más probable que se produzca un sobreajuste en conjuntos de datos más pequeños?\n",
    "\n",
    "- Porque en un conjunto de datos más pequeño, es más probable que los datos de validación se parezcan a los de entrenamiento\n",
    "- Porque no hay suficientes datos para activar todas las circunvoluciones o neuronas\n",
    "- Porque con menos datos, el entrenamiento se llevará a cabo más rápidamente, y es posible que se pierdan algunas características\n",
    "- Porque hay menos probabilidades de que se encuentren todas las características posibles en el proceso de entrenamiento.\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Porque hay menos probabilidades de que se encuentren todas las características posibles en el proceso de entrenamiento. \n",
    "    \n",
    "Sin duda. Un tamaño menor disminuye la probabilidad de que el modelo reconozca todas las características posibles durante el entrenamiento.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Assignment - Attempt the cats vs. dogs Kaggle challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Versión en español](https://github.com/IngCarlaPezzone/tensorflow-1-public/blob/main/C2/W1/assignment/C2W1_Assignment_traducida.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
